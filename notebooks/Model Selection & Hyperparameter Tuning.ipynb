{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "646563ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "train = pd.read_csv('cleaned_train.csv')\n",
    "target = pd.read_csv('cleaned_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c591939",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0a90130",
   "metadata": {},
   "outputs": [],
   "source": [
    "target.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58034dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1999</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1978</td>\n",
       "      <td>1988</td>\n",
       "      <td>119.0</td>\n",
       "      <td>790</td>\n",
       "      <td>163</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1941</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1950</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49</td>\n",
       "      <td>1029</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1965</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>830</td>\n",
       "      <td>290</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0             60         65.0     8450            7            5       2003   \n",
       "1             20         80.0     9600            6            8       1976   \n",
       "2             60         68.0    11250            7            5       2001   \n",
       "3             70         60.0     9550            7            5       1915   \n",
       "4             60         84.0    14260            8            5       2000   \n",
       "...          ...          ...      ...          ...          ...        ...   \n",
       "1455          60         62.0     7917            6            5       1999   \n",
       "1456          20         85.0    13175            6            6       1978   \n",
       "1457          70         66.0     9042            7            9       1941   \n",
       "1458          20         68.0     9717            5            6       1950   \n",
       "1459          20         75.0     9937            5            6       1965   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  GarageFinish  \\\n",
       "0             2003       196.0         706           0  ...             1   \n",
       "1             1976         0.0         978           0  ...             1   \n",
       "2             2002       162.0         486           0  ...             1   \n",
       "3             1970         0.0         216           0  ...             2   \n",
       "4             2000       350.0         655           0  ...             1   \n",
       "...            ...         ...         ...         ...  ...           ...   \n",
       "1455          2000         0.0           0           0  ...             1   \n",
       "1456          1988       119.0         790         163  ...             2   \n",
       "1457          2006         0.0         275           0  ...             1   \n",
       "1458          1996         0.0          49        1029  ...             2   \n",
       "1459          1965         0.0         830         290  ...             0   \n",
       "\n",
       "      GarageQual  GarageCond  PavedDrive  PoolQC  Fence  MiscFeature  \\\n",
       "0              4           4           2       3      4            4   \n",
       "1              4           4           2       3      4            4   \n",
       "2              4           4           2       3      4            4   \n",
       "3              4           4           2       3      4            4   \n",
       "4              4           4           2       3      4            4   \n",
       "...          ...         ...         ...     ...    ...          ...   \n",
       "1455           4           4           2       3      4            4   \n",
       "1456           4           4           2       3      2            4   \n",
       "1457           4           4           2       3      0            2   \n",
       "1458           4           4           2       3      4            4   \n",
       "1459           4           4           2       3      4            4   \n",
       "\n",
       "      SaleType  SaleCondition  SalePrice  \n",
       "0            8              4     208500  \n",
       "1            8              4     181500  \n",
       "2            8              4     223500  \n",
       "3            8              0     140000  \n",
       "4            8              4     250000  \n",
       "...        ...            ...        ...  \n",
       "1455         8              4     175000  \n",
       "1456         8              4     210000  \n",
       "1457         8              4     266500  \n",
       "1458         8              4     142125  \n",
       "1459         8              4     147500  \n",
       "\n",
       "[1460 rows x 80 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.join(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab8a6fd",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c45662a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eb7d02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e3baba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 79)\n",
      "(1, 1460)\n"
     ]
    }
   ],
   "source": [
    "np_train = np.array(train)\n",
    "np_target = np.array(target).reshape(1,-1)\n",
    "print(np_train.shape)\n",
    "print(np_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1344f4eb",
   "metadata": {},
   "source": [
    "### Below code for cross validation to be used within the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "543cd6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index , test_index in kf.split(train):\n",
    "    X_train , X_test = train.iloc[train_index,:],train.iloc[test_index,:]\n",
    "    y_train , y_test = target.iloc[train_index,:] , target.iloc[test_index,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41ebd1c",
   "metadata": {},
   "source": [
    "# Simple Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dc5b1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error of each fold -> [27046.398447716394, 50743.22796183229, 43020.42438049166, 45749.78065070445, 34214.62365453838]\n",
      "Avg error : 40154.89101905664\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "linear_regression = LinearRegression()\n",
    "\n",
    "acc_score = []\n",
    "# Cross Validation\n",
    "for train_index , test_index in kf.split(train):\n",
    "    X_train , X_test = train.iloc[train_index,:],train.iloc[test_index,:]\n",
    "    y_train , y_test = target.iloc[train_index,:] , target.iloc[test_index,:]\n",
    "     \n",
    "    linear_regression.fit(X_train,y_train)\n",
    "    pred_values = linear_regression.predict(X_test)\n",
    "     \n",
    "    acc = mean_squared_error(pred_values , y_test, squared=False)\n",
    "    acc_score.append(acc)\n",
    "     \n",
    "avg_acc_score = sum(acc_score)/5\n",
    " \n",
    "print('error of each fold -> {}'.format(acc_score))\n",
    "print('Avg error : {}'.format(avg_acc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f4b5f2",
   "metadata": {},
   "source": [
    "# Decision Trees for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb8ec84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error of each fold -> [43354.80573384199, 39126.557923685024, 44194.26473928365, 36373.63728427047, 53128.87710654856]\n",
      "Avg error : 43235.628557525946\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "decision_tree = tree.DecisionTreeRegressor()\n",
    "\n",
    "acc_score = []\n",
    "# Cross Validation\n",
    "for train_index , test_index in kf.split(train):\n",
    "    X_train , X_test = train.iloc[train_index,:],train.iloc[test_index,:]\n",
    "    y_train , y_test = target.iloc[train_index,:] , target.iloc[test_index,:]\n",
    "     \n",
    "    decision_tree.fit(X_train,y_train)\n",
    "    pred_values = decision_tree.predict(X_test)\n",
    "     \n",
    "    acc = mean_squared_error(pred_values , y_test, squared=False)\n",
    "    acc_score.append(acc)\n",
    "     \n",
    "avg_acc_score = sum(acc_score)/5\n",
    " \n",
    "print('error of each fold -> {}'.format(acc_score))\n",
    "print('Avg error : {}'.format(avg_acc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fee8d3",
   "metadata": {},
   "source": [
    "# Random Forest for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c077ef90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error of each fold -> [29764.377350184986, 33111.972922870205, 30066.531644414466, 23860.72645253184, 31107.854273454977]\n",
      "Avg error: 29582.292528691294\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfg = RandomForestRegressor(n_estimators = 500, max_depth=10, n_jobs=-1)\n",
    "\n",
    "acc_score = []\n",
    "# Cross Validation\n",
    "for train_index , test_index in kf.split(train):\n",
    "    X_train , X_test = train.iloc[train_index,:],train.iloc[test_index,:]\n",
    "    y_train , y_test = target.iloc[train_index,:] , target.iloc[test_index,:]\n",
    "     \n",
    "    rfg.fit(X_train,y_train)\n",
    "    pred_values = rfg.predict(X_test)\n",
    "     \n",
    "    acc = mean_squared_error(pred_values , y_test, squared=False)\n",
    "    acc_score.append(acc)\n",
    "     \n",
    "avg_acc_score = sum(acc_score)/5\n",
    " \n",
    "print('error of each fold -> {}'.format(acc_score))\n",
    "print('Avg error: {}'.format(avg_acc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c61716",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6fd320f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error of each fold -> [24747.165574191673, 25521.59372756083, 34021.05901795506, 27249.488148390254, 31468.56888830935]\n",
      "Avg error : 28601.575071281433\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgboost = xgb.XGBRegressor(n_jobs=-1, n_estimators = 200)\n",
    "\n",
    "acc_score = []\n",
    "# Cross Validation\n",
    "for train_index , test_index in kf.split(train):\n",
    "    X_train , X_test = train.iloc[train_index,:],train.iloc[test_index,:]\n",
    "    y_train , y_test = target.iloc[train_index,:] , target.iloc[test_index,:]\n",
    "     \n",
    "    xgboost.fit(X_train,y_train)\n",
    "    pred_values = xgboost.predict(X_test)\n",
    "     \n",
    "    acc = mean_squared_error(pred_values , y_test, squared=False)\n",
    "    acc_score.append(acc)\n",
    "     \n",
    "avg_acc_score = sum(acc_score)/5\n",
    " \n",
    "print('error of each fold -> {}'.format(acc_score))\n",
    "print('Avg error : {}'.format(avg_acc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997840e8",
   "metadata": {},
   "source": [
    "# Now that we have observed Random Forest and XGBoost to yield the lowest error, we would now use these models and perform hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e033e58",
   "metadata": {},
   "source": [
    "## First, Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46a709f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bf98156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=RandomForestRegressor(max_depth=10,\n",
       "                                                   n_estimators=500,\n",
       "                                                   n_jobs=-1),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfg = RandomForestRegressor()\n",
    "rf_random = RandomizedSearchCV(estimator = rfg, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 100, \n",
    "                               cv = 5, \n",
    "                               verbose=2, \n",
    "                               random_state=42, \n",
    "                               n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e27ba18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 400,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692923bc",
   "metadata": {},
   "source": [
    "### Now that we have a certain range, we would go in-depth by using Grid Search with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b38e7d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 400}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [False],\n",
    "    'max_features': ['sqrt'],\n",
    "    'min_samples_leaf': [1,2,3],\n",
    "    'min_samples_split': [2,4,6],\n",
    "    'n_estimators': [300,350,400,450]\n",
    "}\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rfg, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 5)\n",
    "\n",
    "grid_search.fit(train, target)\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923d9912",
   "metadata": {},
   "source": [
    "### Let us check the error rate with these hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4079877d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error of each fold -> [27578.85011987219, 28483.52286300223, 32133.065050670863, 30231.49066962668, 28982.775414375865]\n",
      "Avg error: 29481.94082350957\n"
     ]
    }
   ],
   "source": [
    "tuned_rfg = RandomForestRegressor(n_estimators = 400, \n",
    "                                  max_depth=None, \n",
    "                                  bootstrap = False,\n",
    "                                  max_features='sqrt',\n",
    "                                  min_samples_leaf = 1,\n",
    "                                  min_samples_split = 2,\n",
    "                                  n_jobs=-1, )\n",
    "\n",
    "acc_score = []\n",
    "# Cross Validation\n",
    "for train_index , test_index in kf.split(train):\n",
    "    X_train , X_test = train.iloc[train_index,:],train.iloc[test_index,:]\n",
    "    y_train , y_test = target.iloc[train_index,:] , target.iloc[test_index,:]\n",
    "     \n",
    "    rfg.fit(X_train,y_train)\n",
    "    pred_values = rfg.predict(X_test)\n",
    "     \n",
    "    acc = mean_squared_error(pred_values , y_test, squared=False)\n",
    "    acc_score.append(acc)\n",
    "     \n",
    "avg_acc_score = sum(acc_score)/5\n",
    " \n",
    "print('error of each fold -> {}'.format(acc_score))\n",
    "print('Avg error: {}'.format(avg_acc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09046d77",
   "metadata": {},
   "source": [
    "### As we can see, there is a very small reduction in the error rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86b15aa",
   "metadata": {},
   "source": [
    "## Now, let's see XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86e6a912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [2, 3, 4, 5, 6, 7, 8, 9], 'eta': [0.1, 0.3, 0.5, 0.7, 0.9], 'gamma': [0, 1, 2, 3, 4, 5], 'min_child_weight': [0, 1, 2, 3, 4, 5], 'subsample': [0.1, 0.3, 0.5, 0.7, 0.9]}\n"
     ]
    }
   ],
   "source": [
    "max_depth = [2, 3, 4, 5, 6, 7, 8, 9]\n",
    "eta = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "gamma = [0, 1, 2, 3, 4, 5]\n",
    "min_child_weight = [0, 1, 2, 3, 4, 5]\n",
    "subsample = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "# Create the random grid\n",
    "random_grid = {'max_depth': max_depth,\n",
    "               'eta': eta,\n",
    "               'gamma': gamma,\n",
    "               'min_child_weight': min_child_weight,\n",
    "               'subsample': subsample,\n",
    "              }\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e01a6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.7,\n",
       " 'min_child_weight': 2,\n",
       " 'max_depth': 4,\n",
       " 'gamma': 4,\n",
       " 'eta': 0.1}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost = xgb.XGBRegressor(tree_method = 'gpu_hist')\n",
    "xgboost_random = RandomizedSearchCV(estimator = xgboost, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 100, \n",
    "                               cv = 5, \n",
    "                               verbose=3, \n",
    "                               random_state=42, \n",
    "                               n_jobs = -1)\n",
    "# Fit the random search model\n",
    "xgboost_random.fit(train, target)\n",
    "\n",
    "xgboost_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e547a473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 540 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eta': 0.1,\n",
       " 'gamma': 4,\n",
       " 'max_depth': 4,\n",
       " 'min_child_weight': 2.5,\n",
       " 'subsample': 0.75}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'eta': [0.05, 0.1, 0.15],\n",
    "    'gamma': [4, 5, 6, 3],\n",
    "    'min_child_weight': [1.5, 2, 2.5],\n",
    "    'subsample': [0.6, 0.65, 0.7, 0.75, 0.8],\n",
    "}\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = xgboost, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 5)\n",
    "\n",
    "grid_search.fit(train, target)\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cf69b8",
   "metadata": {},
   "source": [
    "### Let us check the error rate with these hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c525ad72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error of each fold -> [27783.847675877158, 30713.134282044884, 27377.758311210826, 23375.72916836421, 23486.60787895418]\n",
      "Avg error : 26547.415463290246\n"
     ]
    }
   ],
   "source": [
    "xgboost = xgb.XGBRegressor(n_jobs=-1, \n",
    "                            eta = 0.1, \n",
    "                            gamma = 4, \n",
    "                            max_depth = 4,\n",
    "                            min_child_weight = 2.5, \n",
    "                            subsample=0.75)\n",
    "\n",
    "acc_score = []\n",
    "# Cross Validation\n",
    "for train_index , test_index in kf.split(train):\n",
    "    X_train , X_test = train.iloc[train_index,:],train.iloc[test_index,:]\n",
    "    y_train , y_test = target.iloc[train_index,:] , target.iloc[test_index,:]\n",
    "     \n",
    "    xgboost.fit(X_train,y_train)\n",
    "    pred_values = xgboost.predict(X_test)\n",
    "     \n",
    "    acc = mean_squared_error(pred_values , y_test, squared=False)\n",
    "    acc_score.append(acc)\n",
    "     \n",
    "avg_acc_score = sum(acc_score)/5\n",
    " \n",
    "print('error of each fold -> {}'.format(acc_score))\n",
    "print('Avg error : {}'.format(avg_acc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bfb445",
   "metadata": {},
   "source": [
    "### We observe that XGBoost also experienced a reducition in error which is great news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b678e6",
   "metadata": {},
   "source": [
    "# Let us now create a stacked model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5350869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    models = dict()\n",
    "    models['rf'] = RandomForestRegressor(n_estimators = 400, \n",
    "                                  max_depth=None, \n",
    "                                  bootstrap = False,\n",
    "                                  max_features='sqrt',\n",
    "                                  min_samples_leaf = 1,\n",
    "                                  min_samples_split = 2,\n",
    "                                  n_jobs=-1, )\n",
    "    models['xgb'] = xgb.XGBRegressor(n_jobs=-1, \n",
    "                            eta = 0.1, \n",
    "                            gamma = 4, \n",
    "                            max_depth = 4,\n",
    "                            min_child_weight = 2.5, \n",
    "                            subsample=0.75)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4693ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cdaf63df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">rf -770344597.410 (281792965.805)\n",
      ">xgb -731955065.145 (351753686.982)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, train, target)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n",
    "# plot model performance for comparison\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6d477dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "# get a stacking ensemble of models\n",
    "def get_stacking():\n",
    "    # define the base models\n",
    "    level0 = list()\n",
    "    level0.append(('rf', RandomForestRegressor(n_estimators = 400, \n",
    "                                  max_depth=None, \n",
    "                                  bootstrap = False,\n",
    "                                  max_features='sqrt',\n",
    "                                  min_samples_leaf = 1,\n",
    "                                  min_samples_split = 2,\n",
    "                                  n_jobs=-1)))\n",
    "    level0.append(('xgb', xgb.XGBRegressor(n_jobs=-1, \n",
    "                            eta = 0.1, \n",
    "                            gamma = 4, \n",
    "                            max_depth = 4,\n",
    "                            min_child_weight = 2.5, \n",
    "                            subsample=0.75)))\n",
    "    # define meta learner model\n",
    "    level1 = LinearRegression()\n",
    "    # define the stacking ensemble\n",
    "    model = StackingRegressor(estimators=level0, final_estimator=level1, cv=5)\n",
    "    return model\n",
    "\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    models['rf'] = RandomForestRegressor(n_estimators = 400, \n",
    "                                  max_depth=None, \n",
    "                                  bootstrap = False,\n",
    "                                  max_features='sqrt',\n",
    "                                  min_samples_leaf = 1,\n",
    "                                  min_samples_split = 2,\n",
    "                                  n_jobs=-1, )\n",
    "    models['xgb'] = xgb.XGBRegressor(n_jobs=-1, \n",
    "                            eta = 0.1, \n",
    "                            gamma = 4, \n",
    "                            max_depth = 4,\n",
    "                            min_child_weight = 2.5, \n",
    "                            subsample=0.75)\n",
    "    models['stacking'] = get_stacking()\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "47320aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">rf -776581887.665 (289335184.230)\n",
      ">xgb -731955065.145 (351753686.982)\n",
      ">stacking -693251630.337 (331565285.712)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model, train, target)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, np.mean(scores), np.std(scores)))\n",
    "# plot model performance for comparison\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11887da9",
   "metadata": {},
   "source": [
    "### Let's see our error value for our stacked model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ab65d683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error of each fold -> [30470.939969898875, 33867.74888162598, 25488.528051647725, 21525.175234184902, 22397.067537472376]\n",
      "Avg error: 26749.89193496597\n"
     ]
    }
   ],
   "source": [
    "# define the base models\n",
    "level0 = list()\n",
    "level0.append(('rf', RandomForestRegressor(n_estimators = 400, \n",
    "                                  max_depth=None, \n",
    "                                  bootstrap = False,\n",
    "                                  max_features='sqrt',\n",
    "                                  min_samples_leaf = 1,\n",
    "                                  min_samples_split = 2,\n",
    "                                  n_jobs=-1)))\n",
    "level0.append(('xgb', xgb.XGBRegressor(n_jobs=-1, \n",
    "                            eta = 0.1, \n",
    "                            gamma = 4, \n",
    "                            max_depth = 4,\n",
    "                            min_child_weight = 2.5, \n",
    "                            subsample=0.75)))\n",
    "# define meta learner model\n",
    "level1 = LinearRegression()\n",
    "# define the stacking ensemble\n",
    "stacked_model = StackingRegressor(estimators=level0, final_estimator=level1, cv=5)\n",
    "\n",
    "acc_score = []\n",
    "# Cross Validation\n",
    "for train_index , test_index in kf.split(train):\n",
    "    X_train , X_test = train.iloc[train_index,:],train.iloc[test_index,:]\n",
    "    y_train , y_test = target.iloc[train_index,:] , target.iloc[test_index,:]\n",
    "     \n",
    "    stacked_model.fit(X_train,y_train)\n",
    "    pred_values = stacked_model.predict(X_test)\n",
    "     \n",
    "    acc = mean_squared_error(pred_values , y_test, squared=False)\n",
    "    acc_score.append(acc)\n",
    "     \n",
    "avg_acc_score = sum(acc_score)/5\n",
    " \n",
    "print('error of each fold -> {}'.format(acc_score))\n",
    "print('Avg error: {}'.format(avg_acc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06273139",
   "metadata": {},
   "source": [
    "## Althought it doesn't seem much different from XGBoost's tuned model, we would proceed to use this model for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "49397114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(stacked_model, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchcuda",
   "language": "python",
   "name": "pytorchcuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
